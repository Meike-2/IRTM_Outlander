{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-14T11:46:54.538114Z",
     "end_time": "2023-05-14T11:46:54.545077Z"
    }
   },
   "outputs": [],
   "source": [
    "books = ['Outlander', 'Dragonfly in Amber', 'Voyager', 'Drums of Autumn', 'The Fiery Cross', 'A Breath of Snow and Ashes',\n",
    "             'An Echo in the Bone', 'Written in My Own Heartâ€™s Blood']\n",
    "extras = ['Other Books by this Author', 'About the Author']\n",
    "bookstarts = [50, 17287, 37378, 61857, 89432, 119494, 152540, 177800, 202059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1675799\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data.txt\", \"r\", encoding=\"utf8\")\n",
    "booknum = 1\n",
    "\n",
    "\n",
    "book = ''\n",
    "i = 0\n",
    "for line in f:\n",
    "    if i < bookstarts[booknum] and i > bookstarts[booknum-1]:\n",
    "        book = book + line\n",
    "    i = i + 1\n",
    "print(len(book))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T13:21:31.083834Z",
     "end_time": "2023-05-14T13:21:31.739277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-14 11:47:50,586 SequenceTagger predicts: Dictionary with 75 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-GPE, B-GPE, E-GPE, I-GPE, S-ORG, B-ORG, E-ORG, I-ORG, S-DATE, B-DATE, E-DATE, I-DATE, S-CARDINAL, B-CARDINAL, E-CARDINAL, I-CARDINAL, S-NORP, B-NORP, E-NORP, I-NORP, S-MONEY, B-MONEY, E-MONEY, I-MONEY, S-PERCENT, B-PERCENT, E-PERCENT, I-PERCENT, S-ORDINAL, B-ORDINAL, E-ORDINAL, I-ORDINAL, S-LOC, B-LOC, E-LOC, I-LOC, S-TIME, B-TIME, E-TIME, I-TIME, S-WORK_OF_ART, B-WORK_OF_ART, E-WORK_OF_ART, I-WORK_OF_ART, S-FAC\n",
      "2023-05-14 11:47:56,308 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence, Token\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger_ner = SequenceTagger.load(\"flair/ner-english-ontonotes-fast\")\n",
    "tagger_pos = SequenceTagger.load(\"flair/pos-english\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T11:47:25.512091Z",
     "end_time": "2023-05-14T11:47:56.614490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def ner_tag(text):\n",
    "    sentence_ner = Sentence(text)\n",
    "\n",
    "    # predict NER tags\n",
    "    tagger_ner.predict(sentence_ner)\n",
    "    return sentence_ner"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T11:47:56.649400Z",
     "end_time": "2023-05-14T11:47:56.653387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def pos_tag(text):\n",
    "   sentence_pos = Sentence(text)\n",
    "\n",
    "   # predict NER tags\n",
    "   tagger_pos.predict(sentence_pos)\n",
    "   return sentence_pos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T11:47:56.658373Z",
     "end_time": "2023-05-14T11:47:56.668347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_person_before(sentence_ner, token):\n",
    "    if token.text=='it':\n",
    "        return token.text\n",
    "    if token.text=='I' or token.text=='me':\n",
    "        return 'Claire'\n",
    "    prev_person = ''\n",
    "    for entity in sentence_ner.get_spans('ner'):\n",
    "        if entity.tag == 'PERSON' and entity.start_position<token.start_position:\n",
    "                prev_person = entity.text\n",
    "        elif entity.start_position>token.start_position:\n",
    "            break\n",
    "    return prev_person"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T11:47:56.678320Z",
     "end_time": "2023-05-14T11:47:56.729185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import re\n",
    "def split_into_chapters(booknum, text):\n",
    "    if booknum <7:\n",
    "        return re.split(r'(\\\\n[0-9]+\\\\n\\\\n)', book)\n",
    "    else:\n",
    "        # needs refinement\n",
    "        return re.split(r'[A-Z ]+\\\\n\\\\n', book)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T13:29:01.049371Z",
     "end_time": "2023-05-14T13:29:01.062339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def split_into_paragraphs(text):\n",
    "    splitted = re.split('(\\*\\*\\*)', text)\n",
    "    return [x for x in splitted if x != '']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T13:13:57.788631Z",
     "end_time": "2023-05-14T13:13:57.814013Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter  0\n",
      "Pos tagging....\n",
      "Ner tagging....\n",
      "Replacing pronouns....\n",
      "Chapter  1\n",
      "Pos tagging....\n"
     ]
    }
   ],
   "source": [
    "chapters = re.split(r'\\n[0-9]+\\n\\n', book)\n",
    "i = 0\n",
    "for chapter in chapters:\n",
    "    paragraphs = split_into_paragraphs(chapter)\n",
    "    for paragraph in paragraphs:\n",
    "        print('Chapter ', i)\n",
    "        print('Pos tagging....')\n",
    "        sentence_pos = pos_tag(paragraph)\n",
    "        print('Ner tagging....')\n",
    "        sentence_ner = ner_tag(paragraph)\n",
    "        no_pronouns_book = Sentence(paragraph.split(' '), use_tokenizer=True)\n",
    "        print('Replacing pronouns....')\n",
    "        i=0\n",
    "        for token in sentence_pos:\n",
    "            if token.tag == 'PRP':\n",
    "                name = get_person_before(sentence_ner, token)\n",
    "                new_token = Token(name)\n",
    "                no_pronouns_book[token.start_position-1].text = name\n",
    "                no_pronouns_book.tokens[token.idx] = new_token\n",
    "        with open('data_no_pronouns.txt', 'w') as f:\n",
    "            f.write(no_pronouns_book.to_original_text())\n",
    "    i+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
