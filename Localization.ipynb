{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\\noindent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "370ff5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdf4d9",
   "metadata": {},
   "source": [
    "#### Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67b2838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the NER gotten from BERT (missing book 1)\n",
    "def read_fromBERT():\n",
    "    nerbert = []\n",
    "    for i in range(2,9):\n",
    "        path = \"BERT/NER_BERT_Book\" + str(i) + \".csv\"\n",
    "        f = open(path, encoding='utf-8', errors='ignore')\n",
    "        lines = f.read()\n",
    "        split = lines.split(\"\\n\")\n",
    "        nerlist = []\n",
    "        for item in split:\n",
    "            line = item.split(',')\n",
    "            if len(line)>2:\n",
    "                nerlist.append([''.join(line[:len(line)-2]), line[-2], line[-1]])\n",
    "        nerbert.append(nerlist)\n",
    "    return nerbert\n",
    "\n",
    "# Reads the NER gotten from FLAIR\n",
    "def read_fromFLAIR():\n",
    "    nerflair = []\n",
    "    for i in range(1, 9): \n",
    "        path = \"NER_FLAIR/ner\" + str(i) + '.txt'\n",
    "        f = open(path, encoding='utf-8')\n",
    "        lines = f.readlines()\n",
    "        nerlist = []\n",
    "        for line in lines:\n",
    "            split = line.split(\" \")\n",
    "            nerlist.append([' '.join(split[:len(split)-2]), split[-2], split[-1][:-2]])\n",
    "        nerflair.append(nerlist)\n",
    "    return nerflair\n",
    "\n",
    "# reads the location information with longitude and latitides from csv\n",
    "def read_locs():\n",
    "    return pd.read_csv('locs_lonlat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c833925",
   "metadata": {},
   "source": [
    "#### Select only people and locations from ner lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb9967ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selects only the people and the locations from the input NERS\n",
    "def select_people_and_locs_only(nerfrombert):\n",
    "    peopleandlocs = []\n",
    "    for book in nerfrombert:\n",
    "        for ner in book:\n",
    "            if ner[1] == 'B-PER' or ner[1] == 'PERSON':\n",
    "                peopleandlocs.append(ner)\n",
    "            elif ner[1] == 'B-LOC' or ner[1] == 'GPE' or ner[1] == 'LOC':\n",
    "                peopleandlocs.append(ner)\n",
    "    return peopleandlocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0c954",
   "metadata": {},
   "source": [
    "### Localization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f0e3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximity_measure(inputners, proximity, person='Claire'):\n",
    "    locslist = []\n",
    "    for i in range(len(inputners)):\n",
    "        if inputners[i][0] == person:\n",
    "            index = int(inputners[i][2])\n",
    "            curloc = []\n",
    "            \n",
    "            # look further\n",
    "            for j in range(1,len(inputners)-i):\n",
    "                if inputners[i+j-1][2] <= inputners[i+j][2] and int(inputners[i+j][2])-index <= proximity:\n",
    "                    if inputners[i+j][1] == 'B-LOC' or inputners[i+j][1] == 'LOC' or inputners[i+j][1] == 'GPE':\n",
    "                        curloc.append(inputners[i+j][0])\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            # look back\n",
    "            for j in range(1, len(inputners)):\n",
    "                if inputners[i-j-1][2] >= inputners[i-j][2] and index-int(inputners[i-j][2]) <= proximity:\n",
    "                    if inputners[i-j][1] == 'B-LOC'or inputners[i-j][1] == 'LOC' or inputners[i-j][1] == 'GPE':\n",
    "                        curloc.append(inputners[i-j][0])\n",
    "                else:\n",
    "                    break\n",
    "            locslist.append([index, curloc])   \n",
    "    return locslist\n",
    "\n",
    "def get_coordinates(locations):\n",
    "    totallonglats = []\n",
    "    for entry in locations:\n",
    "        longlats = []\n",
    "        for location in entry[1]:\n",
    "            found = locinformation[locinformation['Name'] == location]\n",
    "            if len(found) > 0:\n",
    "                long = found['Longitude'].item()\n",
    "                lat = found['Latitude'].item()\n",
    "                if long is not None and lat is not None and long != 'None' and lat != 'None':\n",
    "                    longlats.append([location, long, lat])\n",
    "        if len(longlats) > 0:\n",
    "            totallonglats.append(longlats)\n",
    "    return totallonglats\n",
    "\n",
    "def get_innercluster_loc(longlats):\n",
    "    finalentities = []\n",
    "    for entity in longlats:\n",
    "        smallesttotal = float('inf')\n",
    "        bestindex = 0\n",
    "        for i in range(len(entity)):\n",
    "            totaldist = 0\n",
    "            for j in range(1, len(entity)-i):\n",
    "                totaldist = totaldist + (float(entity[i][1]) - float(entity[j][1]))**2 + (float(entity[i][2]) - float(entity[j][2]))**2\n",
    "\n",
    "            if totaldist < smallesttotal:\n",
    "                smallesttotal = totaldist\n",
    "                bestindex = i\n",
    "        finalentities.append(entity[i][0])\n",
    "    return finalentities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4edd8d7",
   "metadata": {},
   "source": [
    "### Deploy Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "426dff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read locations\n",
    "locinformation = read_locs()\n",
    "\n",
    "# read ners flair and select only people and locs\n",
    "nerflair = read_fromFLAIR()\n",
    "peoplelocsflair = select_people_and_locs_only(nerflair)\n",
    "\n",
    "# read ners bert and select only people and locs\n",
    "nerbert = read_fromBERT()\n",
    "peoplelocsbert = select_people_and_locs_only(nerbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12f8b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "locationsflair = proximity_measure(peoplelocsflair[10000:12000], 10000, 'Claire')\n",
    "longlatsflair = get_coordinates(locationsflair)\n",
    "finallocsflair = get_innercluster_loc(longlatsflair)\n",
    "\n",
    "locationsbert = proximity_measure(peoplelocsbert[:2000], 30, 'Claire')\n",
    "longlatsbert = get_coordinates(locationsbert)\n",
    "finallocsbert = get_innercluster_loc(longlatsbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c23d057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Cumberland',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'London',\n",
       " 'Fort William',\n",
       " 'Fort William',\n",
       " 'London',\n",
       " 'Highlands',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Cumberland',\n",
       " 'London',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Culloden',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Loch Ness',\n",
       " 'Loch Ness',\n",
       " 'Loch Ness',\n",
       " 'Loch Ness',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Culloden',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Edinburgh',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Culloden',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'America',\n",
       " 'Prestonpans',\n",
       " 'Prestonpans',\n",
       " 'Prestonpans',\n",
       " 'Prestonpans',\n",
       " 'Prestonpans',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Massachusetts',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Oxford',\n",
       " 'Inverness',\n",
       " 'Inverness',\n",
       " 'Massachusetts',\n",
       " 'Massachusetts',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Massachusetts',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Inverness',\n",
       " 'Inverness',\n",
       " 'Inverness',\n",
       " 'Inverness',\n",
       " 'Inverness',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Inverness',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Inverness',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Inverness',\n",
       " 'Inverness',\n",
       " 'Inverness',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Scotland',\n",
       " 'Cumberland',\n",
       " 'Cumberland',\n",
       " 'Cumberland',\n",
       " 'Cumberland',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands',\n",
       " 'Highlands']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finallocsbert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
