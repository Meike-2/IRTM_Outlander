{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-14T12:20:03.691844Z",
     "end_time": "2023-05-14T12:20:16.005914Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bookwise preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T12:08:01.170983Z",
     "end_time": "2023-05-14T12:08:01.249769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "books = ['Outlander', 'Dragonfly in Amber', 'Voyager', 'Drums of Autumn', 'The Fiery Cross', 'A Breath of Snow and Ashes',\n",
    "         'An Echo in the Bone', 'Written in My Own Heart’s Blood']\n",
    "extras = ['Other Books by this Author', 'About the Author']\n",
    "bookstarts = [50, 17287, 37378, 61857, 89432, 119494, 152540, 177800, 202059]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:10:40.999155Z",
     "end_time": "2023-05-15T18:10:41.017142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = open(\"data.txt\", \"r\", encoding=\"utf8\")\n",
    "booknum = 1\n",
    "\n",
    "\n",
    "book = ''\n",
    "i = 0\n",
    "for line in f:\n",
    "    if i < bookstarts[booknum] and i > bookstarts[booknum-1]:\n",
    "        book = book + line\n",
    "    i = i + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:10:41.899399Z",
     "end_time": "2023-05-15T18:10:42.756198Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we want to segment the data into chapters as we want to see the topic per chapter. But how do we do that?\n",
    "# the author devided the books into parts, this is how we can see when hte first chapter begins, then we search for a line\n",
    "# that is written in all caps, after this the chapter starts: example: \\n\\n\\n\\n\\n\\n1\\n\\nA NEW BEGINNING\\n\\n\n",
    "#\n",
    "# book 1 has 41, 49, 63, 71, 111, 124, 103, 145\n",
    "# found is 41, 49, 63, 71, 111, 124, 0, 0\n",
    "def split_into_chapters(booknum, text):\n",
    "    if booknum <7:\n",
    "        return re.split(r'\\n[0-9]+\\n\\n', book)\n",
    "    else:\n",
    "        # needs refinement\n",
    "        return re.split(r'[A-Z ]+\\n\\n', book)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:10:43.661852Z",
     "end_time": "2023-05-15T18:10:43.681822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_into_paragraphs(text):\n",
    "    splitted = re.split('(\\*\\*\\*)', text)\n",
    "    return [x for x in splitted if x != '']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:10:44.840757Z",
     "end_time": "2023-05-15T18:10:44.855719Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(split_into_paragraphs(split_into_chapters(1, book)[4]))\n",
    "sentences = split_into_paragraphs(split_into_chapters(1, book)[0])\n",
    "sentences[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:10:45.710709Z",
     "end_time": "2023-05-15T18:10:45.764989Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Linguistic Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "per_paragraph = True\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"[a-zA-Z’]+\")\n",
    "chapters = split_into_chapters(booknum, book)\n",
    "tchapters = []\n",
    "for chapter in chapters:\n",
    "    tparagraphs = []\n",
    "    if per_paragraph:\n",
    "        paragraphs = split_into_paragraphs(chapter)\n",
    "        for paragraph in paragraphs:\n",
    "            tparagraphs.append(tokenizer.tokenize(paragraph))\n",
    "        tchapters.append(tparagraphs)\n",
    "    else:\n",
    "        tchapters.append(tokenizer.tokenize(chapter))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:10:47.839954Z",
     "end_time": "2023-05-15T18:10:47.855071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chapternum = 0\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "if not per_paragraph:\n",
    "    for word in tchapters[chapternum]:\n",
    "        print(lemmatizer.lemmatize(word))\n",
    "else:\n",
    "    for paragraph in tchapters[chapternum]:\n",
    "        for word in paragraph:\n",
    "            print(lemmatizer.lemmatize(word))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:10:48.700947Z",
     "end_time": "2023-05-15T18:10:50.489546Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FLAIR NER Tagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install flair"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T18:16:51.284083Z",
     "end_time": "2023-05-15T18:16:57.288772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from flair.data import Sentence, Token\n",
    "from flair.models import SequenceTagger\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tagger = SequenceTagger.load(\"flair/ner-english-ontonotes-fast\")\n",
    "\n",
    "locations = []\n",
    "chapters = re.split(r'\\n[0-9]+\\n\\n', book)\n",
    "l = 0\n",
    "for chapter in chapters:\n",
    "    sentence = Sentence(chapter)\n",
    "    tagger.predict(sentence)\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        with open('ner1.txt', 'a') as f:\n",
    "                f.write(entity.text)\n",
    "                f.write(entity.tag)\n",
    "                f.write(str(entity.start_position+l))\n",
    "                f.write('\\n')\n",
    "        if entity.tag=='GPE':\n",
    "            locations.append(entity.text)\n",
    "            with open('locs1.txt', 'a') as f:\n",
    "                f.write(entity.text)\n",
    "                f.write('\\n')\n",
    "    l += len(chapter)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T12:27:19.360681Z",
     "end_time": "2023-05-14T12:30:47.866133Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
